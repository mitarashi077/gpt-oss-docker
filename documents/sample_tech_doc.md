# GPT-OSS Docker RAG システム技術文書

## 概要

GPT-OSS Docker RAGシステムは、ローカル環境で動作する検索拡張生成（Retrieval-Augmented Generation）システムです。このシステムは以下のコンポーネントで構成されています：

- **Ollama**: オープンソースのLLMエンジン
- **Qdrant**: 高性能ベクトルデータベース
- **Sentence Transformers**: テキストエンベディングエンジン
- **FastAPI**: RESTful API サーバー

## アーキテクチャ

### 1. データフロー

1. **文書アップロード**: ユーザーが文書（PDF、テキスト）をアップロード
2. **チャンク分割**: 文書を検索しやすいサイズに分割
3. **ベクトル化**: Sentence Transformersでエンベディング生成
4. **インデックス**: Qdrantにベクトルとメタデータを保存
5. **検索**: ユーザークエリを同じモデルでベクトル化し、類似度検索
6. **生成**: 検索結果をコンテキストとしてOllamaで回答生成

### 2. サービス構成

- **ollama:11434** - LLM推論エンジン
- **qdrant:6333** - ベクトルDB管理画面
- **embeddings:8001** - エンベディングAPI

## 技術仕様

### エンベディングモデル
- モデル名: all-MiniLM-L6-v2
- 次元数: 384
- 言語: 多言語対応（日本語含む）

### ベクトルデータベース
- エンジン: Qdrant
- 距離メトリック: コサイン類似度
- インデックス: HNSW

### LLMモデル
- デフォルト: llama2:7b
- 代替: codellama:7b
- 最大トークン: 4096

## API仕様

### POST /upload
文書をアップロードしてインデックス作成

### POST /search
クエリで関連文書を検索

### GET /health
サービス状態を確認

## パフォーマンス

- チャンク分割: 500文字（50文字オーバーラップ）
- 検索レスポンス: ~100ms
- 生成レスポンス: ~5-30秒（モデルサイズ依存）

## セキュリティ

- ローカル実行（外部通信なし）
- データ永続化（Docker volumes）
- CORS設定済み